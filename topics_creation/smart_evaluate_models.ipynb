{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d94fa0-976b-48f3-a95e-d53a4c34ac4d",
   "metadata": {},
   "source": [
    "## This is a smarter way to evaluate the crucial steps of the BERTopic model, avoiding to have to create a complete model for each configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5ecf94-5e4f-4ef3-9a35-922ebcc6ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 03:05:45.609510: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 03:05:45.731634: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-17 03:05:46.876266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-01-17 03:05:46.876360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-01-17 03:05:46.876365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported sections: 11827\n",
      "Creating embeddings manually...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9dfc2daf32441792b387fa72898523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual 384-dimensional embeddings created!\n"
     ]
    }
   ],
   "source": [
    "# Import the sections and create manual embeddings\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import statistics\n",
    "import numpy as np\n",
    "import json\n",
    "from bertopic.backend import BaseEmbedder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "\n",
    "# First we import the files\n",
    "our_flyers_path = 'flyers_text.json'\n",
    "\n",
    "with open(our_flyers_path, 'r') as file:\n",
    "    json_file = json.load(file)\n",
    "\n",
    "# The list of sections to analyze is the list of values of each value of the original dictionary (json file)\n",
    "sections_dict = {} # The dictionary is to avoid repeated elements\n",
    "saw_sections = []\n",
    "counter = -1\n",
    "for document in json_file.values(): \n",
    "    counter += 1\n",
    "    for section in document.values(): \n",
    "        if section not in saw_sections:\n",
    "            sections_dict[section] = counter\n",
    "            saw_sections.append(section)\n",
    "\n",
    "sections = list(sections_dict.keys())\n",
    "document_id_list = list(sections_dict.values())\n",
    "\n",
    "print(\"Imported sections:\", len(sections))\n",
    "\n",
    "class CustomEmbedder(BaseEmbedder):\n",
    "    def __init__(self, embedding_model):\n",
    "        super().__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    def embed(self, documents, verbose=False):\n",
    "        embeddings = self.embedding_model.encode(documents, show_progress_bar=verbose)\n",
    "        return embeddings \n",
    "    \n",
    "embedding_model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "custom_embedder = CustomEmbedder(embedding_model=embedding_model)\n",
    "\n",
    "print(\"Creating embeddings manually...\")\n",
    "manual_embeddings = custom_embedder.embed(sections, verbose=True)\n",
    "print(\"Manual 384-dimensional embeddings created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa83d51-e455-4840-992c-e5a544cdbebb",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a97893-dbfa-4b9f-a962-2cc27d90ae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration: 0\n",
      "Evaluating configation 5 of 100\n",
      "Evaluating configation 10 of 100\n",
      "Evaluating configation 15 of 100\n",
      "Evaluating configation 20 of 100\n",
      "Evaluating configation 25 of 100\n",
      "Evaluating configation 30 of 100\n",
      "Evaluating configation 35 of 100\n",
      "Evaluating configation 40 of 100\n",
      "Evaluating configation 45 of 100\n",
      "Evaluating configation 50 of 100\n",
      "Evaluating configation 55 of 100\n",
      "Evaluating configation 60 of 100\n",
      "Evaluating configation 65 of 100\n",
      "Evaluating configation 70 of 100\n",
      "Evaluating configation 75 of 100\n",
      "Evaluating configation 80 of 100\n",
      "Evaluating configation 85 of 100\n",
      "Evaluating configation 90 of 100\n",
      "Evaluating configation 95 of 100\n",
      "Evaluating configation 100 of 100\n",
      "Starting iteration: 1\n",
      "Evaluating configation 5 of 100\n",
      "Evaluating configation 10 of 100\n",
      "Evaluating configation 15 of 100\n",
      "Evaluating configation 20 of 100\n",
      "Evaluating configation 25 of 100\n",
      "Evaluating configation 30 of 100\n",
      "Evaluating configation 35 of 100\n",
      "Evaluating configation 40 of 100\n",
      "Evaluating configation 45 of 100\n",
      "Evaluating configation 50 of 100\n",
      "Evaluating configation 55 of 100\n",
      "Evaluating configation 60 of 100\n",
      "Evaluating configation 65 of 100\n",
      "Evaluating configation 70 of 100\n",
      "Evaluating configation 75 of 100\n",
      "Evaluating configation 80 of 100\n",
      "Evaluating configation 85 of 100\n",
      "Evaluating configation 90 of 100\n",
      "Evaluating configation 95 of 100\n",
      "Evaluating configation 100 of 100\n",
      "Starting iteration: 2\n",
      "Evaluating configation 5 of 100\n",
      "Evaluating configation 10 of 100\n",
      "Evaluating configation 15 of 100\n",
      "Evaluating configation 20 of 100\n",
      "Evaluating configation 25 of 100\n",
      "Evaluating configation 30 of 100\n",
      "Evaluating configation 35 of 100\n",
      "Evaluating configation 40 of 100\n",
      "Evaluating configation 45 of 100\n",
      "Evaluating configation 50 of 100\n",
      "Evaluating configation 55 of 100\n",
      "Evaluating configation 60 of 100\n",
      "Evaluating configation 65 of 100\n",
      "Evaluating configation 70 of 100\n",
      "Evaluating configation 75 of 100\n",
      "Evaluating configation 80 of 100\n",
      "Evaluating configation 85 of 100\n",
      "Evaluating configation 90 of 100\n",
      "Evaluating configation 95 of 100\n",
      "Evaluating configation 100 of 100\n",
      "Starting iteration: 3\n",
      "Evaluating configation 5 of 100\n",
      "Evaluating configation 10 of 100\n",
      "Evaluating configation 15 of 100\n",
      "Evaluating configation 20 of 100\n",
      "Evaluating configation 25 of 100\n",
      "Evaluating configation 30 of 100\n",
      "Evaluating configation 35 of 100\n",
      "Evaluating configation 40 of 100\n",
      "Evaluating configation 45 of 100\n",
      "Evaluating configation 50 of 100\n",
      "Evaluating configation 55 of 100\n",
      "Evaluating configation 60 of 100\n",
      "Evaluating configation 65 of 100\n",
      "Evaluating configation 70 of 100\n",
      "Evaluating configation 75 of 100\n",
      "Evaluating configation 80 of 100\n",
      "Evaluating configation 85 of 100\n",
      "Evaluating configation 90 of 100\n",
      "Evaluating configation 95 of 100\n",
      "Evaluating configation 100 of 100\n",
      "Used time: 1.9204771969715755 hours.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score, normalized_mutual_info_score\n",
    "#from sklearn.cluster import HDBSCAN\n",
    "from hdbscan import HDBSCAN\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def add_noise(embeddings, noise_sd=0.01): \n",
    "    \n",
    "    noisy_embeddings = embeddings.copy()\n",
    "\n",
    "    for index,embedding in enumerate(noisy_embeddings): \n",
    "        noise = np.random.normal(0,noise_sd, len(embedding))\n",
    "        noisy_embeddings[index] += noise\n",
    "        \n",
    "    return noisy_embeddings\n",
    "\n",
    "def geometric_evaluation(embeddings_, labels_): \n",
    "\n",
    "    # Distance metrics\n",
    "    DB_score = davies_bouldin_score(embeddings_, labels_) # The lower the better\n",
    "    CH_score = calinski_harabasz_score(embeddings_, labels_) # The higher the better\n",
    "    S_score = silhouette_score(embeddings_, labels_, metric=\"cosine\") # The higher the better\n",
    "    \n",
    "    return DB_score, CH_score, S_score\n",
    "\n",
    "def robustness_evaluation(labels, noisy_labels): \n",
    "\n",
    "    # Robustness metrics\n",
    "    AR_score = adjusted_rand_score(labels,noisy_labels) # The higher the better\n",
    "    AMI_score = adjusted_mutual_info_score(labels,noisy_labels) # The higher the better\n",
    "    NMI_score = normalized_mutual_info_score(labels,noisy_labels) # The higher the better\n",
    "    \n",
    "    return AR_score, AMI_score, NMI_score\n",
    "\n",
    "def semantic_evaluation(labels):\n",
    "    \n",
    "    # Create sublists with the labels assigned to sections in the same document (including outliers)\n",
    "    prev = 0\n",
    "    doc_labels = []\n",
    "    docs_labels_list = []\n",
    "    for index,element in enumerate(document_id_list): \n",
    "        if element == prev:\n",
    "            doc_labels.append(labels[index])\n",
    "        else: \n",
    "            docs_labels_list.append(doc_labels)\n",
    "            doc_labels = []\n",
    "            doc_labels.append(labels[index])\n",
    "        prev = element\n",
    "    docs_labels_list.append(doc_labels)\n",
    "\n",
    "    # Take the cluster that is the most frequent and see how frequent it is in the list\n",
    "    scores_list = []\n",
    "    for doc in docs_labels_list: # Each doc is a lists with the labels of its sections\n",
    "        # Find the most repeated label in the document\n",
    "        most_freq_label = max(set(doc), key=doc.count)\n",
    "        # Find how many time does that label appear and compare it with the total quantity of labels (sections) of the doc\n",
    "        label_repetitions = doc.count(most_freq_label)\n",
    "        score = (label_repetitions/len(doc))*100\n",
    "        scores_list.append(score)\n",
    "\n",
    "    # Compute the total score weighting the score of each doc with its number of sections\n",
    "    sum_of_scores = 0\n",
    "    for index,doc in enumerate(docs_labels_list): \n",
    "        sum_of_scores += scores_list[index]*len(doc)\n",
    "\n",
    "    weighted_score = sum_of_scores/len(labels)\n",
    "\n",
    "    '''\n",
    "    This metric as it is is not very intuitive, because it is upper bounded by 84.68% (because we discard repeated sections) and\n",
    "    lower bounded by the score that we would get if no repeated section would be in any document (11.16%) (REALLYYYYY??????)\n",
    "\n",
    "    Then, we should rescale it!\n",
    "    '''\n",
    "\n",
    "    return weighted_score\n",
    "\n",
    "initial_time = time.time()\n",
    "\n",
    "iters = [1,2,3,4]\n",
    "\n",
    "for it in iters:\n",
    "\n",
    "    dimension_of_embeddings = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "    min_cluster_sizes = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "    counter = 0\n",
    "\n",
    "    list_of_lists_of_number_of_clusters = []\n",
    "    list_of_lists_of_outliers = []\n",
    "    list_of_lists_of_DB_scores = []\n",
    "    list_of_lists_of_CH_scores = []\n",
    "    list_of_lists_of_S_scores = []\n",
    "    list_of_lists_of_AR_scores = []\n",
    "    list_of_lists_of_AMI_scores = []\n",
    "    list_of_lists_of_NMI_scores = []\n",
    "    list_of_lists_of_sem_scores = []\n",
    "\n",
    "    for i in dimension_of_embeddings: \n",
    "\n",
    "        list_of_number_of_clusters = []\n",
    "        list_of_outliers = []\n",
    "        list_of_DB_scores = []\n",
    "        list_of_CH_scores = []\n",
    "        list_of_S_scores = []\n",
    "        list_of_AR_scores = []\n",
    "        list_of_AMI_scores = []\n",
    "        list_of_NMI_scores = []\n",
    "        list_of_sem_scores = []\n",
    "\n",
    "        for j in min_cluster_sizes:\n",
    "\n",
    "            counter += 1\n",
    "            if counter == 1: \n",
    "                print(\"Starting iteration:\", it - iters[0])\n",
    "            if counter % 5 == 0:\n",
    "                print(f\"Evaluating configation {counter} of {len(dimension_of_embeddings)*len(min_cluster_sizes)}\")\n",
    "            #print(\"Executing reduction of dimensionality by UMAP model...\")\n",
    "            umap_model = UMAP(n_neighbors=15, n_components=i, min_dist=0.0, metric='cosine')\n",
    "            embeddings = umap_model.fit_transform(manual_embeddings)\n",
    "            #print(\"UMAP embeddings created!\")\n",
    "\n",
    "            #print(\"Generating noisy embeddings...\")\n",
    "            noisy_embeddings = add_noise(embeddings, noise_sd=0.05)\n",
    "\n",
    "            #print(\"Executing HDBSCAN...\")\n",
    "            hdbscan_model = HDBSCAN(min_cluster_size=j, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "            #hdbscan_model = HDBSCAN(min_cluster_size=j, metric='cosine', cluster_selection_method='eom')\n",
    "            labels = hdbscan_model.fit_predict(embeddings)\n",
    "            number_of_clusters = len(set(labels))\n",
    "\n",
    "            noisy_labels = hdbscan_model.fit_predict(noisy_embeddings)\n",
    "            #print(\"Clusters computed by HDBSCAN!\")\n",
    "\n",
    "            #print(\"Remove outliers before applying geometrical evaluation\")\n",
    "            labels_ = []\n",
    "            embeddings_ = []\n",
    "            noisy_labels_ = []\n",
    "            outliers_counter = 0\n",
    "            for index,element in enumerate(labels): \n",
    "                if element != -1: \n",
    "                    labels_.append(element)\n",
    "                    embeddings_.append(embeddings[index])\n",
    "                    noisy_labels_.append(noisy_labels[index]) # ATTENTION: I DON'T REMEMBER THE OUTLIERS IN THE NOISY_LABELS, \n",
    "                    # BUT THOSE POSITIONS WHERE OUTLIERS WHERE SPOTTED IN THE HEALTHY LABELS! IF CLUSTERS ARE ROBUST, THEY SHOULD BE THE SAME!!!!!\n",
    "                else: \n",
    "                    outliers_counter += 1\n",
    "\n",
    "\n",
    "            #print(\"Computing geometric evaluation...\")\n",
    "            DB_score, CH_score, S_score = geometric_evaluation(embeddings_, labels_)\n",
    "\n",
    "            #print(\"Computing robustness evaluation...\")\n",
    "            AR_score, AMI_score, NMI_score = robustness_evaluation(labels_, noisy_labels_)\n",
    "\n",
    "            #print(\"Computing semantic evaluation...\")\n",
    "            semantic_score = semantic_evaluation(labels)\n",
    "\n",
    "            list_of_number_of_clusters.append(number_of_clusters)\n",
    "            list_of_outliers.append(outliers_counter)\n",
    "            list_of_DB_scores.append(DB_score)\n",
    "            list_of_CH_scores.append(CH_score)\n",
    "            list_of_S_scores.append(S_score)\n",
    "            list_of_AR_scores.append(AR_score)\n",
    "            list_of_AMI_scores.append(AMI_score)\n",
    "            list_of_NMI_scores.append(NMI_score)\n",
    "            list_of_sem_scores.append(semantic_score)\n",
    "\n",
    "        list_of_lists_of_number_of_clusters.append(list_of_number_of_clusters)\n",
    "        list_of_lists_of_outliers.append(list_of_outliers)\n",
    "        list_of_lists_of_DB_scores.append(list_of_DB_scores)\n",
    "        list_of_lists_of_CH_scores.append(list_of_CH_scores)\n",
    "        list_of_lists_of_S_scores.append(list_of_S_scores)\n",
    "        list_of_lists_of_AR_scores.append(list_of_AR_scores)\n",
    "        list_of_lists_of_AMI_scores.append(list_of_AMI_scores)\n",
    "        list_of_lists_of_NMI_scores.append(list_of_NMI_scores)\n",
    "        list_of_lists_of_sem_scores.append(list_of_sem_scores)\n",
    "        \n",
    "    list_of_lists_of_number_of_clusters_np = np.array(list_of_lists_of_number_of_clusters)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_number_of_clusters.csv', list_of_lists_of_number_of_clusters_np, delimiter=',')\n",
    "    list_of_lists_of_outliers_np = np.array(list_of_lists_of_outliers)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_outliers.csv', list_of_lists_of_outliers, delimiter=',')\n",
    "    list_of_lists_of_DB_scores_np = np.array(list_of_lists_of_DB_scores)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_DB_scores_np.csv', list_of_lists_of_DB_scores_np, delimiter=',')\n",
    "    list_of_lists_of_CH_scores_np = np.array(list_of_lists_of_CH_scores)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_CH_scores_np.csv', list_of_lists_of_CH_scores_np, delimiter=',')\n",
    "    list_of_lists_of_S_scores_np = np.array(list_of_lists_of_S_scores)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_S_scores_np.csv', list_of_lists_of_S_scores_np, delimiter=',')\n",
    "    list_of_lists_of_AR_scores_np = np.array(list_of_lists_of_AR_scores)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_AR_scores_np.csv', list_of_lists_of_AR_scores_np, delimiter=',')\n",
    "    list_of_lists_of_AMI_scores_np = np.array(list_of_lists_of_AMI_scores)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_AMI_scores_np.csv', list_of_lists_of_AMI_scores_np, delimiter=',')\n",
    "    list_of_lists_of_NMI_scores_np = np.array(list_of_lists_of_NMI_scores)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_NMI_scores_np.csv', list_of_lists_of_NMI_scores_np, delimiter=',')\n",
    "    list_of_lists_of_sem_scores_np = np.array(list_of_lists_of_sem_scores)\n",
    "    np.savetxt(f'scoring/list_{it}_of_lists_of_sem_scores_np.csv', list_of_lists_of_sem_scores_np, delimiter=',')\n",
    "    \n",
    "    list_of_lists_of_number_of_clusters_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_number_of_clusters.csv', delimiter=',')\n",
    "    list_of_lists_of_outliers_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_outliers.csv', delimiter=',')\n",
    "    list_of_lists_of_DB_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_DB_scores_np.csv', delimiter=',')\n",
    "    list_of_lists_of_CH_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_CH_scores_np.csv', delimiter=',')\n",
    "    list_of_lists_of_S_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_S_scores_np.csv', delimiter=',')\n",
    "    list_of_lists_of_AR_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_AR_scores_np.csv', delimiter=',')\n",
    "    list_of_lists_of_AMI_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_AMI_scores_np.csv', delimiter=',')\n",
    "    list_of_lists_of_NMI_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_NMI_scores_np.csv', delimiter=',')\n",
    "    list_of_lists_of_sem_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_sem_scores_np.csv', delimiter=',')\n",
    "    \n",
    "    arrays_list = [list_of_lists_of_number_of_clusters_np, list_of_lists_of_outliers_np, list_of_lists_of_DB_scores_np, \\\n",
    "                   list_of_lists_of_CH_scores_np, list_of_lists_of_S_scores_np, \\\n",
    "                  list_of_lists_of_AR_scores_np, list_of_lists_of_AMI_scores_np, list_of_lists_of_NMI_scores_np, list_of_lists_of_sem_scores_np]\n",
    "    titles_list = [f'Clusters {it}', f'Outliers {it}', f'DB {it} scores (geometry)', f'CH {it} scores (geometry)', f'S {it} score (geometry)', \\\n",
    "                   f'AR {it} score (robustness)', f'AMI {it} scores (robustness)', f'NMI {it} scores (robustness)', f'Semantic {it} scores']\n",
    "\n",
    "    for index,array in enumerate(arrays_list): \n",
    "        plt.imshow(np.flipud(array), cmap='coolwarm') \n",
    "        plt.colorbar() \n",
    "        plt.title(titles_list[index]) \n",
    "        plt.xticks(np.arange(array.shape[1]), [5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "        plt.yticks(np.arange(array.shape[0]), [50, 45, 40, 35, 30, 25, 20, 15, 10, 5])\n",
    "        plt.xlabel('Minimum cluster size') \n",
    "        plt.ylabel('Embeddings dimensionality')\n",
    "        plt.savefig(\"images/\"+titles_list[index]+'.png')\n",
    "        plt.close()\n",
    "    \n",
    "final_time = time.time()\n",
    "used_time = final_time - initial_time\n",
    "print(\"Used time:\", used_time/3600, \"hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07896e8-ae7d-43df-9974-caf0d55a2b8a",
   "metadata": {},
   "source": [
    "## RESULTS VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50cb29e9-364f-49e8-beb8-4bc3453d6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "it = 10\n",
    "\n",
    "list_of_lists_of_number_of_clusters_np = np.array(list_of_lists_of_number_of_clusters)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_number_of_clusters.csv', list_of_lists_of_number_of_clusters_np, delimiter=',')\n",
    "list_of_lists_of_outliers_np = np.array(list_of_lists_of_outliers)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_outliers.csv', list_of_lists_of_outliers, delimiter=',')\n",
    "list_of_lists_of_DB_scores_np = np.array(list_of_lists_of_DB_scores)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_DB_scores_np.csv', list_of_lists_of_DB_scores_np, delimiter=',')\n",
    "list_of_lists_of_CH_scores_np = np.array(list_of_lists_of_CH_scores)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_CH_scores_np.csv', list_of_lists_of_CH_scores_np, delimiter=',')\n",
    "list_of_lists_of_S_scores_np = np.array(list_of_lists_of_S_scores)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_S_scores_np.csv', list_of_lists_of_S_scores_np, delimiter=',')\n",
    "list_of_lists_of_AR_scores_np = np.array(list_of_lists_of_AR_scores)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_AR_scores_np.csv', list_of_lists_of_AR_scores_np, delimiter=',')\n",
    "list_of_lists_of_AMI_scores_np = np.array(list_of_lists_of_AMI_scores)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_AMI_scores_np.csv', list_of_lists_of_AMI_scores_np, delimiter=',')\n",
    "list_of_lists_of_NMI_scores_np = np.array(list_of_lists_of_NMI_scores)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_NMI_scores_np.csv', list_of_lists_of_NMI_scores_np, delimiter=',')\n",
    "list_of_lists_of_sem_scores_np = np.array(list_of_lists_of_sem_scores)\n",
    "np.savetxt(f'scoring/list_{it}_of_lists_of_sem_scores_np.csv', list_of_lists_of_sem_scores_np, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d8d6cb-d3b8-4f52-af4b-6570ebd4cddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists_of_number_of_clusters_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_number_of_clusters.csv', delimiter=',')\n",
    "list_of_lists_of_outliers_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_outliers.csv', delimiter=',')\n",
    "list_of_lists_of_DB_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_DB_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_CH_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_CH_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_S_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_S_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_AR_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_AR_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_AMI_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_AMI_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_NMI_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_NMI_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_sem_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_sem_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_number_of_clusters_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad28d711-9ea3-4b89-853b-6b50d5a444aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.imshow(list_of_lists_of_DB_scores_np_, cmap='coolwarm') \\nplt.colorbar() \\nplt.title('DB scores (geometry)') \\nplt.xticks(np.arange(list_of_lists_of_DB_scores_np.shape[1]), [5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\\nplt.yticks(np.arange(list_of_lists_of_DB_scores_np.shape[0]), [50, 45, 40, 35, 30, 25, 20, 15, 10, 5])\\nplt.xlabel('Minimum cluster size') \\nplt.ylabel('Embeddings dimensionality')\\nplt.show()\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DB scores\n",
    "list_of_lists_of_DB_scores_np_ = np.flipud(list_of_lists_of_number_of_clusters_np)\n",
    "list_of_lists_of_DB_scores_np_\n",
    "'''plt.imshow(list_of_lists_of_DB_scores_np_, cmap='coolwarm') \n",
    "plt.colorbar() \n",
    "plt.title('DB scores (geometry)') \n",
    "plt.xticks(np.arange(list_of_lists_of_DB_scores_np.shape[1]), [5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "plt.yticks(np.arange(list_of_lists_of_DB_scores_np.shape[0]), [50, 45, 40, 35, 30, 25, 20, 15, 10, 5])\n",
    "plt.xlabel('Minimum cluster size') \n",
    "plt.ylabel('Embeddings dimensionality')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07989b5b-007d-4de8-bd7b-0dbcd3bc8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_list = [list_of_lists_of_number_of_clusters_np, list_of_lists_of_outliers_np, list_of_lists_of_DB_scores_np, \\\n",
    "               list_of_lists_of_CH_scores_np, list_of_lists_of_S_scores_np, \\\n",
    "              list_of_lists_of_AR_scores_np, list_of_lists_of_AMI_scores_np, list_of_lists_of_NMI_scores_np, list_of_lists_of_sem_scores_np]\n",
    "titles_list = [f'Clusters {it}', f'Outliers {it}', f'DB {it} scores (geometry)', f'CH {it} scores (geometry)', f'S {it} score (geometry)', \\\n",
    "               f'AR {it} score (robustness)', f'AMI {it} scores (robustness)', f'NMI {it} scores (robustness)', f'Semantic {it} scores']\n",
    "\n",
    "for index,array in enumerate(arrays_list): \n",
    "    plt.imshow(np.flipud(array), cmap='coolwarm') \n",
    "    plt.colorbar() \n",
    "    plt.title(titles_list[index]) \n",
    "    plt.xticks(np.arange(array.shape[1]), [5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    plt.yticks(np.arange(array.shape[0]), [50, 45, 40, 35, 30, 25, 20, 15, 10, 5])\n",
    "    plt.xlabel('Minimum cluster size') \n",
    "    plt.ylabel('Embeddings dimensionality')\n",
    "    plt.savefig(\"images/\"+titles_list[index]+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec4cb8e-12b1-4e1b-8d35-4d94560a9407",
   "metadata": {},
   "source": [
    "## A variant of the previous evaluation strategy to test a concrete model multiple times and get its results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5be8b1fb-4880-43fd-883e-928cfac2e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported sections: 11827\n",
      "Creating embeddings manually...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b66e413aefb4dc69847b43541af01bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual 384-dimensional embeddings created!\n"
     ]
    }
   ],
   "source": [
    "# Import the sections and create manual embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1f76b-be33-49bc-9b4f-92c1a34875cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6268e8bb-3544-4263-af2d-d544df3f6779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n",
      "Importing sections...\n",
      "Imported sections: 11827\n",
      "Creating embeddings for iteration 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6085a1a68c8d48e4b58c43e25fbac96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Creating embeddings for iteration 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73d10fbe7a14016a26c96a0b7991a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Creating embeddings for iteration 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9add557282b54423a0032c03d795d117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Creating embeddings for iteration 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58596a44bbbf450aaab36e9a925b07c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Creating embeddings for iteration 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b41f8ea1a634533adbf9e7428b2b6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Clusters average: 153.0\n",
      "Outliers average: 4288.0\n",
      "DB scores (geometry) average: 0.421093617204376\n",
      "CH scores (geometry) average: 7176.469281512615\n",
      "S score (geometry) average: 0.7744507\n",
      "AR score (robustness) average: 0.6445819077117131\n",
      "AMI scores (robustness) average: 0.8732230007214775\n",
      "NMI scores (robustness) average: 0.8936709501788663\n",
      "Semantic scores average: 48.60911473746512\n",
      "Used time: 14.390301020940145 mins.\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing libraries...\")\n",
    "from bertopic import BERTopic\n",
    "import statistics\n",
    "import numpy as np\n",
    "import json\n",
    "from bertopic.backend import BaseEmbedder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score, normalized_mutual_info_score\n",
    "#from sklearn.cluster import HDBSCAN\n",
    "from hdbscan import HDBSCAN\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def add_noise(embeddings, noise_sd=0.01): \n",
    "    \n",
    "    noisy_embeddings = embeddings.copy()\n",
    "\n",
    "    for index,embedding in enumerate(noisy_embeddings): \n",
    "        noise = np.random.normal(0,noise_sd, len(embedding))\n",
    "        noisy_embeddings[index] += noise\n",
    "        \n",
    "    return noisy_embeddings\n",
    "\n",
    "def geometric_evaluation(embeddings_, labels_): \n",
    "\n",
    "    # Distance metrics\n",
    "    DB_score = davies_bouldin_score(embeddings_, labels_) # The lower the better\n",
    "    CH_score = calinski_harabasz_score(embeddings_, labels_) # The higher the better\n",
    "    S_score = silhouette_score(embeddings_, labels_, metric=\"cosine\") # The higher the better\n",
    "    \n",
    "    return DB_score, CH_score, S_score\n",
    "\n",
    "def robustness_evaluation(labels, noisy_labels): \n",
    "\n",
    "    # Robustness metrics\n",
    "    AR_score = adjusted_rand_score(labels,noisy_labels) # The higher the better\n",
    "    AMI_score = adjusted_mutual_info_score(labels,noisy_labels) # The higher the better\n",
    "    NMI_score = normalized_mutual_info_score(labels,noisy_labels) # The higher the better\n",
    "    \n",
    "    return AR_score, AMI_score, NMI_score\n",
    "\n",
    "def semantic_evaluation(labels):\n",
    "    \n",
    "    # Create sublists with the labels assigned to sections in the same document (including outliers)\n",
    "    prev = 0\n",
    "    doc_labels = []\n",
    "    docs_labels_list = []\n",
    "    for index,element in enumerate(document_id_list): \n",
    "        if element == prev:\n",
    "            doc_labels.append(labels[index])\n",
    "        else: \n",
    "            docs_labels_list.append(doc_labels)\n",
    "            doc_labels = []\n",
    "            doc_labels.append(labels[index])\n",
    "        prev = element\n",
    "    docs_labels_list.append(doc_labels)\n",
    "\n",
    "    # Take the cluster that is the most frequent and see how frequent it is in the list\n",
    "    scores_list = []\n",
    "    for doc in docs_labels_list: # Each doc is a lists with the labels of its sections\n",
    "        # Find the most repeated label in the document\n",
    "        most_freq_label = max(set(doc), key=doc.count)\n",
    "        # Find how many time does that label appear and compare it with the total quantity of labels (sections) of the doc\n",
    "        label_repetitions = doc.count(most_freq_label)\n",
    "        score = (label_repetitions/len(doc))*100\n",
    "        scores_list.append(score)\n",
    "\n",
    "    # Compute the total score weighting the score of each doc with its number of sections\n",
    "    sum_of_scores = 0\n",
    "    for index,doc in enumerate(docs_labels_list): \n",
    "        sum_of_scores += scores_list[index]*len(doc)\n",
    "\n",
    "    weighted_score = sum_of_scores/len(labels)\n",
    "\n",
    "    '''\n",
    "    This metric as it is is not very intuitive, because it is upper bounded by 84.68% (because we discard repeated sections) and\n",
    "    lower bounded by the score that we would get if no repeated section would be in any document (11.16%) (REALLYYYYY??????)\n",
    "\n",
    "    Then, we should rescale it!\n",
    "    '''\n",
    "\n",
    "    return weighted_score\n",
    "\n",
    "initial_time = time.time()\n",
    "\n",
    "# First we import the files\n",
    "our_flyers_path = 'flyers_text.json'\n",
    "\n",
    "print(\"Importing sections...\")\n",
    "with open(our_flyers_path, 'r') as file:\n",
    "    json_file = json.load(file)\n",
    "\n",
    "# The list of sections to analyze is the list of values of each value of the original dictionary (json file)\n",
    "sections_dict = {} # The dictionary is to avoid repeated elements\n",
    "saw_sections = []\n",
    "counter = -1\n",
    "for document in json_file.values(): \n",
    "    counter += 1\n",
    "    for section in document.values(): \n",
    "        if section not in saw_sections:\n",
    "            sections_dict[section] = counter\n",
    "            saw_sections.append(section)\n",
    "\n",
    "sections = list(sections_dict.keys())\n",
    "document_id_list = list(sections_dict.values())\n",
    "\n",
    "print(\"Imported sections:\", len(sections))\n",
    "\n",
    "class CustomEmbedder(BaseEmbedder):\n",
    "    def __init__(self, embedding_model):\n",
    "        super().__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    def embed(self, documents, verbose=False):\n",
    "        embeddings = self.embedding_model.encode(documents, show_progress_bar=verbose)\n",
    "        return embeddings \n",
    "\n",
    "iters = 5\n",
    "\n",
    "for it in range(iters):\n",
    "    \n",
    "    embedding_model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\")\n",
    "    custom_embedder = CustomEmbedder(embedding_model=embedding_model)\n",
    "\n",
    "    print(f\"Creating embeddings for iteration {it+1}\")\n",
    "    manual_embeddings = custom_embedder.embed(sections, verbose=True)\n",
    "    print(\"Starting evaluation...\")\n",
    "\n",
    "    dimension_of_embeddings = [10]\n",
    "    min_cluster_sizes = [15]\n",
    "    counter = 0\n",
    "\n",
    "    list_of_lists_of_number_of_clusters = []\n",
    "    list_of_lists_of_outliers = []\n",
    "    list_of_lists_of_DB_scores = []\n",
    "    list_of_lists_of_CH_scores = []\n",
    "    list_of_lists_of_S_scores = []\n",
    "    list_of_lists_of_AR_scores = []\n",
    "    list_of_lists_of_AMI_scores = []\n",
    "    list_of_lists_of_NMI_scores = []\n",
    "    list_of_lists_of_sem_scores = []\n",
    "\n",
    "    for i in dimension_of_embeddings: \n",
    "\n",
    "        list_of_number_of_clusters = []\n",
    "        list_of_outliers = []\n",
    "        list_of_DB_scores = []\n",
    "        list_of_CH_scores = []\n",
    "        list_of_S_scores = []\n",
    "        list_of_AR_scores = []\n",
    "        list_of_AMI_scores = []\n",
    "        list_of_NMI_scores = []\n",
    "        list_of_sem_scores = []\n",
    "\n",
    "        for j in min_cluster_sizes:\n",
    "\n",
    "            counter += 1\n",
    "            if counter == 1: \n",
    "                #print(\"Starting iteration:\", it - iters[0])\n",
    "                pass\n",
    "            if counter % 5 == 0:\n",
    "                #print(f\"Evaluating configation {counter} of {len(dimension_of_embeddings)*len(min_cluster_sizes)}\")\n",
    "                pass\n",
    "            #print(\"Executing reduction of dimensionality by UMAP model...\")\n",
    "            umap_model = UMAP(n_neighbors=15, n_components=i, min_dist=0.0, metric='cosine')\n",
    "            embeddings = umap_model.fit_transform(manual_embeddings)\n",
    "            #print(\"UMAP embeddings created!\")\n",
    "\n",
    "            #print(\"Generating noisy embeddings...\")\n",
    "            noisy_embeddings = add_noise(embeddings, noise_sd=0.05)\n",
    "\n",
    "            #print(\"Executing HDBSCAN...\")\n",
    "            hdbscan_model = HDBSCAN(min_cluster_size=j, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "            #hdbscan_model = HDBSCAN(min_cluster_size=j, metric='cosine', cluster_selection_method='eom')\n",
    "            labels = hdbscan_model.fit_predict(embeddings)\n",
    "            number_of_clusters = len(set(labels))\n",
    "\n",
    "            noisy_labels = hdbscan_model.fit_predict(noisy_embeddings)\n",
    "            #print(\"Clusters computed by HDBSCAN!\")\n",
    "\n",
    "            #print(\"Remove outliers before applying geometrical evaluation\")\n",
    "            labels_ = []\n",
    "            embeddings_ = []\n",
    "            noisy_labels_ = []\n",
    "            outliers_counter = 0\n",
    "            for index,element in enumerate(labels): \n",
    "                if element != -1: \n",
    "                    labels_.append(element)\n",
    "                    embeddings_.append(embeddings[index])\n",
    "                    noisy_labels_.append(noisy_labels[index]) # ATTENTION: I DON'T REMEMBER THE OUTLIERS IN THE NOISY_LABELS, \n",
    "                    # BUT THOSE POSITIONS WHERE OUTLIERS WHERE SPOTTED IN THE HEALTHY LABELS! IF CLUSTERS ARE ROBUST, THEY SHOULD BE THE SAME!!!!!\n",
    "                else: \n",
    "                    outliers_counter += 1\n",
    "\n",
    "\n",
    "            #print(\"Computing geometric evaluation...\")\n",
    "            DB_score, CH_score, S_score = geometric_evaluation(embeddings_, labels_)\n",
    "\n",
    "            #print(\"Computing robustness evaluation...\")\n",
    "            AR_score, AMI_score, NMI_score = robustness_evaluation(labels_, noisy_labels_)\n",
    "\n",
    "            #print(\"Computing semantic evaluation...\")\n",
    "            semantic_score = semantic_evaluation(labels)\n",
    "\n",
    "            list_of_number_of_clusters.append(number_of_clusters)\n",
    "            list_of_outliers.append(outliers_counter)\n",
    "            list_of_DB_scores.append(DB_score)\n",
    "            list_of_CH_scores.append(CH_score)\n",
    "            list_of_S_scores.append(S_score)\n",
    "            list_of_AR_scores.append(AR_score)\n",
    "            list_of_AMI_scores.append(AMI_score)\n",
    "            list_of_NMI_scores.append(NMI_score)\n",
    "            list_of_sem_scores.append(semantic_score)\n",
    "\n",
    "        list_of_lists_of_number_of_clusters.append(list_of_number_of_clusters[0])\n",
    "        list_of_lists_of_outliers.append(list_of_outliers[0])\n",
    "        list_of_lists_of_DB_scores.append(list_of_DB_scores[0])\n",
    "        list_of_lists_of_CH_scores.append(list_of_CH_scores[0])\n",
    "        list_of_lists_of_S_scores.append(list_of_S_scores[0])\n",
    "        list_of_lists_of_AR_scores.append(list_of_AR_scores[0])\n",
    "        list_of_lists_of_AMI_scores.append(list_of_AMI_scores[0])\n",
    "        list_of_lists_of_NMI_scores.append(list_of_NMI_scores[0])\n",
    "        list_of_lists_of_sem_scores.append(list_of_sem_scores[0])\n",
    "        \n",
    "list_of_lists_of_number_of_clusters_np = np.array(list_of_lists_of_number_of_clusters)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_number_of_clusters.csv', list_of_lists_of_number_of_clusters_np, delimiter=',')\n",
    "list_of_lists_of_outliers_np = np.array(list_of_lists_of_outliers)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_outliers.csv', list_of_lists_of_outliers, delimiter=',')\n",
    "list_of_lists_of_DB_scores_np = np.array(list_of_lists_of_DB_scores)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_DB_scores_np.csv', list_of_lists_of_DB_scores_np, delimiter=',')\n",
    "list_of_lists_of_CH_scores_np = np.array(list_of_lists_of_CH_scores)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_CH_scores_np.csv', list_of_lists_of_CH_scores_np, delimiter=',')\n",
    "list_of_lists_of_S_scores_np = np.array(list_of_lists_of_S_scores)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_S_scores_np.csv', list_of_lists_of_S_scores_np, delimiter=',')\n",
    "list_of_lists_of_AR_scores_np = np.array(list_of_lists_of_AR_scores)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_AR_scores_np.csv', list_of_lists_of_AR_scores_np, delimiter=',')\n",
    "list_of_lists_of_AMI_scores_np = np.array(list_of_lists_of_AMI_scores)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_AMI_scores_np.csv', list_of_lists_of_AMI_scores_np, delimiter=',')\n",
    "list_of_lists_of_NMI_scores_np = np.array(list_of_lists_of_NMI_scores)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_NMI_scores_np.csv', list_of_lists_of_NMI_scores_np, delimiter=',')\n",
    "list_of_lists_of_sem_scores_np = np.array(list_of_lists_of_sem_scores)\n",
    "#np.savetxt(f'scoring/list_{it}_of_lists_of_sem_scores_np.csv', list_of_lists_of_sem_scores_np, delimiter=',')\n",
    "    \n",
    "'''list_of_lists_of_number_of_clusters_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_number_of_clusters.csv', delimiter=',')\n",
    "list_of_lists_of_outliers_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_outliers.csv', delimiter=',')\n",
    "list_of_lists_of_DB_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_DB_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_CH_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_CH_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_S_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_S_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_AR_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_AR_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_AMI_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_AMI_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_NMI_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_NMI_scores_np.csv', delimiter=',')\n",
    "list_of_lists_of_sem_scores_np = np.genfromtxt(f'scoring/list_{it}_of_lists_of_sem_scores_np.csv', delimiter=',')'''\n",
    "    \n",
    "arrays_list = [list_of_lists_of_number_of_clusters_np, list_of_lists_of_outliers_np, list_of_lists_of_DB_scores_np, \\\n",
    "                list_of_lists_of_CH_scores_np, list_of_lists_of_S_scores_np, \\\n",
    "                list_of_lists_of_AR_scores_np, list_of_lists_of_AMI_scores_np, list_of_lists_of_NMI_scores_np, list_of_lists_of_sem_scores_np]\n",
    "titles_list = [f'Clusters', f'Outliers', f'DB scores (geometry)', f'CH scores (geometry)', f'S score (geometry)', \\\n",
    "                f'AR score (robustness)', f'AMI scores (robustness)', f'NMI scores (robustness)', f'Semantic scores']\n",
    "\n",
    "'''for index,array in enumerate(arrays_list): \n",
    "    plt.imshow(np.flipud(array), cmap='coolwarm') \n",
    "    plt.colorbar() \n",
    "    plt.title(titles_list[index]) \n",
    "    plt.xticks(np.arange(array.shape[1]), [5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    plt.yticks(np.arange(array.shape[0]), [50, 45, 40, 35, 30, 25, 20, 15, 10, 5])\n",
    "    plt.xlabel('Minimum cluster size') \n",
    "    plt.ylabel('Embeddings dimensionality')\n",
    "    plt.savefig(\"images/\"+titles_list[index]+'.png')\n",
    "    plt.close()'''\n",
    "    \n",
    "# Print the average of each one of the measurements: \n",
    "    \n",
    "for index, array in enumerate(arrays_list): \n",
    "    print(f\"{titles_list[index]} average:\", np.mean(array))\n",
    "    \n",
    "final_time = time.time()\n",
    "used_time = final_time - initial_time\n",
    "print(\"Used time:\", used_time/60, \"mins.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
